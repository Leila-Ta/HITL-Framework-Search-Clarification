HITL-Framework-Search-Clarification
Bridging Human Judgments and LLMs: A Human-In-The-Loop Framework for Search Clarifications
This repository contains the dataset, prompt templates, and implementation details for the paper:

Bridging Human Judgments and LLMs: A Human-In-The-Loop Framework for Search Clarifications
Leila Tavakoli, Hamed Zamani
Accepted for SIGIR 2025

The paper introduces a Human-In-The-Loop (HITL) workflow for improving annotation quality in search clarification tasks. We evaluate multiple Large Language Models (LLMs) to assess their ability to replicate human judgments and propose an efficient hybrid approach that reduces human effort while maintaining annotation quality.
